{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Confounding on X-ray data - Asymptotic Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ATE estimation\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from causalml.inference.meta import BaseSRegressor\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Custom modules\n",
    "from feature_extraction.pretrained_models_xrv import load_torchxrayvision_model, extract_features_from_folder\n",
    "from utils.project import set_root\n",
    "from utils.io import save_results, load_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory, dataset directory and directory for saving results\n",
    "set_root()\n",
    "dataset_dir = \"data/xray/processed/all_unique\"\n",
    "results_dir = \"results/asym_normality/xray/label\"\n",
    "\n",
    "# Define the model name and path for saving results\n",
    "model_name = \"densenet121-res224-all\"  # Pretrained model name\n",
    "save_dir_rep = f\"data/xray/representations/{model_name}\"\n",
    "\n",
    "# Define file paths\n",
    "features_path = os.path.join(save_dir_rep, \"latent_features.npy\")\n",
    "labels_path = os.path.join(save_dir_rep, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction and saving (Only if the features and labels do not already exist)\n",
    "if not os.path.exists(features_path) or not os.path.exists(labels_path):\n",
    "    print(f\"Extracting features using model '{model_name}'...\")\n",
    "    \n",
    "    # Extract features and save them\n",
    "    model = load_torchxrayvision_model(model_name)\n",
    "    all_features, labels = extract_features_from_folder(\n",
    "        dataset_dir,\n",
    "        model,\n",
    "        device='cpu',\n",
    "        batch_size=32,\n",
    "        save_path=save_dir_rep\n",
    "    )\n",
    "    \n",
    "    print(f\"Features extracted and saved to: {save_dir_rep}\")\n",
    "else:\n",
    "    print(f\"Features already exist in {save_dir_rep}. Skipping extraction.\")\n",
    "\n",
    "# Load extracted features\n",
    "all_features = np.load(features_path)\n",
    "labels = np.load(labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounding Simulation and ATE Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define simulation parameters\n",
    "beta_true = 2.0     # True effect of A on Y\n",
    "gamma_true = -1   # Effect of pneumonia on Y\n",
    "p_treat_given_pneu = 0.7    # Probability of treatment if pneumonia\n",
    "p_treat_given_normal = 0.3  # Probability of treatment if normal\n",
    "\n",
    "# 2. Specify general parameters for simulation\n",
    "pneumonia_label = labels.astype(int) # ensure 0/1\n",
    "n_samples = pneumonia_label.shape[0]\n",
    "n_runs = 200  # Number of simulation runs\n",
    "ci_alpha_level = 0.05  # Alpha level for 1-alpha confidence intervals\n",
    "z_score = norm.ppf(1 - ci_alpha_level / 2) # Z-score for 1-alpha confidence intervals\n",
    "\n",
    "# 3. Initialize dictionaries to store estimates and confidence intervals\n",
    "methods = ['Naive', 'Oracle', 'S-Learner (Linear)', 'DML (Linear)']\n",
    "estimates_dict = {method: [] for method in methods}\n",
    "cis_dict = {method: {'se': [], 'lower': [], 'upper': []} for method in methods}\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "# 4. Simulation Loop\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n--- Simulation Run {run + 1} ---\")\n",
    "    # Set a unique seed for each run for variability\n",
    "    seed = seed + 2  # Update seed for each run\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 4.1. Simulate Treatment A\n",
    "    pA = pneumonia_label * p_treat_given_pneu + (1 - pneumonia_label) * p_treat_given_normal\n",
    "    A = np.random.binomial(1, pA)\n",
    "    \n",
    "    # 4.2. Simulate Outcome Y\n",
    "    noise = np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "    Y = beta_true * A + gamma_true * pneumonia_label + noise\n",
    "    \n",
    "    # 4.3. Package into DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Y': Y,\n",
    "        'A': A,\n",
    "        'pneumonia': pneumonia_label\n",
    "    })\n",
    "    \n",
    "    # 4.4. Naive OLS (Unadjusted) using statsmodels\n",
    "    X_naive = sm.add_constant(df['A']) \n",
    "    model_naive = sm.OLS(df['Y'], X_naive).fit()\n",
    "    beta_naive = model_naive.params['A']\n",
    "    se_naive = model_naive.bse['A']\n",
    "    ci_lower_naive = beta_naive - z_score * se_naive\n",
    "    ci_upper_naive = beta_naive + z_score * se_naive\n",
    "    estimates_dict['Naive'].append(beta_naive)\n",
    "    cis_dict['Naive']['se'].append(se_naive)\n",
    "    cis_dict['Naive']['lower'].append(ci_lower_naive)\n",
    "    cis_dict['Naive']['upper'].append(ci_upper_naive)\n",
    "    print(f\"Naive OLS: β = {beta_naive:.3f}, SE = {se_naive:.3f}\")\n",
    "    \n",
    "    # 4.5. Oracle OLS (Adjusting for pneumonia) using statsmodels\n",
    "    X_oracle = sm.add_constant(df[['A', 'pneumonia']])\n",
    "    model_oracle = sm.OLS(df['Y'], X_oracle).fit()\n",
    "    beta_oracle = model_oracle.params['A']\n",
    "    se_oracle = model_oracle.bse['A']\n",
    "    ci_lower_oracle = beta_oracle - z_score * se_oracle\n",
    "    ci_upper_oracle = beta_oracle + z_score * se_oracle\n",
    "    estimates_dict['Oracle'].append(beta_oracle)\n",
    "    cis_dict['Oracle']['se'].append(se_oracle)\n",
    "    cis_dict['Oracle']['lower'].append(ci_lower_oracle)\n",
    "    cis_dict['Oracle']['upper'].append(ci_upper_oracle)\n",
    "    print(f\"Oracle OLS: β = {beta_oracle:.3f}, SE = {se_oracle:.3f}\")\n",
    "\n",
    "    # 4.6.1 S-Learner (Linear)\n",
    "    outcome_model_linear = LinearRegression()\n",
    "    try:\n",
    "        outcome_model_linear = BaseSRegressor(outcome_model_linear) \n",
    "        s_ate_linear, s_ci_lower_linear , s_ci_upper_linear  = outcome_model_linear.estimate_ate(all_features, A, Y, return_ci=True)\n",
    "        estimates_dict['S-Learner (Linear)'].append(s_ate_linear[0])\n",
    "        se_slearner = (s_ci_upper_linear - s_ate_linear) / z_score\n",
    "        cis_dict['S-Learner (Linear)']['se'].append(se_slearner)\n",
    "        cis_dict['S-Learner (Linear)']['lower'].append(s_ci_lower_linear[0])\n",
    "        cis_dict['S-Learner (Linear)']['upper'].append(s_ci_upper_linear[0])\n",
    "        print(f\"S-Learner (Linear): β = {s_ate_linear[0]:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: S-Learner (Linear) failed with error: {e}\")\n",
    "        estimates_dict['S-Learner (Linear)'].append(np.nan)\n",
    "        cis_dict['S-Learner (Linear)']['se'].append(np.nan)\n",
    "        cis_dict['S-Learner (Linear)']['lower'].append(np.nan)\n",
    "        cis_dict['S-Learner (Linear)']['upper'].append(np.nan)\n",
    "\n",
    "    # 4.7. DoubleML with Linar Nuisance Estimators\n",
    "    # Convert all_features to DataFrame\n",
    "    X_dml_df = pd.DataFrame(\n",
    "        all_features,\n",
    "        columns=[f\"feat_{i}\" for i in range(all_features.shape[1])]\n",
    "    )\n",
    "\n",
    "    # Add outcome and treatment to DoubleMLData via column names\n",
    "    X_dml_df['Y'] = df['Y'].copy()\n",
    "    X_dml_df['A'] = df['A'].copy()\n",
    "\n",
    "    # Create DoubleMLData\n",
    "    data_dml = DoubleMLData(X_dml_df, \"Y\", \"A\")\n",
    "\n",
    "    # 4.7.1. DoubleML with Linear Models Estimators\n",
    "    try:\n",
    "        # Define nuisance models with linear models\n",
    "        ml_g_linear = LinearRegression() # Outcome model\n",
    "        ml_m_linear = LogisticRegression()  # Treatment model\n",
    "    \n",
    "        # Instantiate and fit DoubleMLPLR\n",
    "        dml_plr_linear = DoubleMLPLR(data_dml, ml_g_linear, ml_m_linear, n_folds=2) \n",
    "        dml_plr_linear.fit()\n",
    "        beta_dml_linear = dml_plr_linear.coef[0]\n",
    "        se_dml_linear = dml_plr_linear.se[0]\n",
    "        estimates_dict['DML (Linear)'].append(beta_dml_linear)\n",
    "        # 95% Confidence Interval\n",
    "        ci_lower_dml_linear = beta_dml_linear - z_score * se_dml_linear\n",
    "        ci_upper_dml_linear = beta_dml_linear + z_score * se_dml_linear\n",
    "        cis_dict['DML (Linear)']['se'].append(se_dml_linear)\n",
    "        cis_dict['DML (Linear)']['lower'].append(ci_lower_dml_linear)\n",
    "        cis_dict['DML (Linear)']['upper'].append(ci_upper_dml_linear)\n",
    "        print(f\"DML (Linear): β = {beta_dml_linear:.3f}, SE = {se_dml_linear:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML (NN) failed with error: {e}\")\n",
    "        estimates_dict['DML (Linear)'].append(np.nan)\n",
    "        cis_dict['DML (Linear)']['se'].append(np.nan)\n",
    "        cis_dict['DML (Linear)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (Linear)']['upper'].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a directory for the experiment and save the results\n",
    "experiment_name = \"exp_results\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_dir = os.path.join(results_dir, model_name, experiment_name, timestamp)\n",
    "save_results(experiment_dir, estimates_dict, cis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the previous experiment\n",
    "estimates_dict, cis_dict = load_results(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize ATE estimates  \n",
    "dml_est_normalized = (np.array(estimates_dict['DML (Linear)']) - \n",
    "                      beta_true) / np.array(cis_dict['DML (Linear)']['se'])\n",
    "naive_est_normalized = (np.array(estimates_dict['Naive']) - \n",
    "                      beta_true) / np.array(cis_dict['Naive']['se'])\n",
    "oracle_est_normalized = (np.array(estimates_dict['Oracle']) - \n",
    "                      beta_true) / np.array(cis_dict['Oracle']['se'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plotting\n",
    "sns.set(style=\"whitegrid\")\n",
    "face_colors = sns.color_palette('pastel')\n",
    "edge_colors = sns.color_palette('dark')\n",
    "\n",
    "fig_orth_nosplit, ax = plt.subplots(constrained_layout=True)\n",
    "\n",
    "n_bins = 20\n",
    "sns.histplot(naive_est_normalized,\n",
    "                color=face_colors[1], edgecolor = edge_colors[1],\n",
    "                stat='density', bins=n_bins, label='Naive')\n",
    "sns.histplot(oracle_est_normalized,\n",
    "                color=face_colors[0], edgecolor = edge_colors[0],\n",
    "                stat='density', bins=n_bins, label='Oracle')\n",
    "sns.histplot(dml_est_normalized,\n",
    "                color=face_colors[2], edgecolor = edge_colors[2],\n",
    "                stat='density', bins=n_bins, label='DML')\n",
    "x_val_norm = np.arange(-15, 15, 0.001)\n",
    "y_val_norm = norm.pdf(x_val_norm)\n",
    "ax.plot(x_val_norm, y_val_norm, color='k', label='$\\\\mathcal{N}(0, 1)$', linewidth=2)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "ax.set_xlim([-15, 5])\n",
    "ax.set_xlabel('$(\\widehat{ATE} - ATE)/\\hat{\\sigma}$')\n",
    "plot_path = os.path.join(experiment_dir, 'plot_asym_norm.pdf')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretrained-causal-adj)",
   "language": "python",
   "name": "pretrained-causal-adj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
