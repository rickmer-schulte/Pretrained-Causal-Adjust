{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Confounding on IMDb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ATE estimation\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from causalml.inference.meta import BaseSRegressor\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Custom modules\n",
    "from utils.project import set_root\n",
    "from utils.io import save_results, load_results\n",
    "from visualization.plotting import plot_ate_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory and directory for saving results\n",
    "set_root()\n",
    "results_dir = \"results/comparison_learners/imdb/label\"\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"densenet121-res224-all\"  # Pretrained model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = \"data/imdb/imdb_with_hidden_states_sentiment.csv\"\n",
    "df_imdb_sent_prepro = pd.read_csv(file_path)\n",
    "\n",
    "# Convert the 'hidden_state' column from string to actual lists\n",
    "df_imdb_sent_prepro['hidden_state'] = df_imdb_sent_prepro['hidden_state'].apply(ast.literal_eval)\n",
    "\n",
    "# Expand the 'hidden_state' column into separate columns\n",
    "hidden_state_df = pd.DataFrame(df_imdb_sent_prepro['hidden_state'].tolist())\n",
    "\n",
    "# Rename the hidden state columns\n",
    "hidden_state_df.columns = [f\"hidden_state_{i}\" for i in range(hidden_state_df.shape[1])]\n",
    "\n",
    "# Concatenate the expanded hidden states with the original DataFrame (excluding original 'hidden_state' column)\n",
    "df_imdb_prepro = pd.concat([df_imdb_sent_prepro.drop(columns=['hidden_state']), hidden_state_df], axis=1)\n",
    "\n",
    "# Drop the 'text' column containing the review text\n",
    "df_imdb = df_imdb_prepro.drop(columns=['text'])\n",
    "\n",
    "# Depict the first few rows of the DataFrame\n",
    "df_imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further preprcessing the dataset for the simulation\n",
    "\n",
    "# Subsample the dataset to a manageable size for simulation\n",
    "n = 1000  # Number of samples to draw for simulation\n",
    "df_imdb_sampled = df_imdb.sample(n=n, replace=False, random_state=42) \n",
    "\n",
    "# Extract sentiment labels and latent representations\n",
    "sent_label = df_imdb_sampled['label']\n",
    "imdb_latent_rep = df_imdb_sampled.drop(columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Confounding Simulation and ATE Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define simulation parameters\n",
    "beta_true = 2.0     # True effect of A on Y\n",
    "gamma_true = -1   # Effect of sentiment label on Y\n",
    "p_treat_given_pos = 0.7    # Probability of treatment if positive sentiment\n",
    "p_treat_given_neg = 0.3  # Probability of treatment if negative sentiment\n",
    "\n",
    "# 2. Specify general parameters for simulation\n",
    "n_samples = imdb_latent_rep.shape[0]  # Sample size\n",
    "n_runs = 5  # Number of simulation runs\n",
    "ci_alpha_level = 0.05  # Alpha level for 1-alpha confidence intervals\n",
    "z_score = norm.ppf(1 - ci_alpha_level / 2) # Z-score for 1-alpha confidence intervals\n",
    "\n",
    "# 3. Initialize dictionaries to store estimates and confidence intervals\n",
    "methods = ['Naive', 'Oracle', 'S-Learner (Linear)', 'S-Learner (RF)', 'S-Learner (Lasso)', 'DML (Linear)', 'DML (RF)', 'DML (Lasso)']\n",
    "estimates_dict = {method: [] for method in methods}\n",
    "cis_dict = {method: {'lower': [], 'upper': []} for method in methods}\n",
    "\n",
    "# 4. Simulation Loop\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n--- Simulation Run {run + 1} ---\")\n",
    "    # Set a unique seed for each run for variability\n",
    "    seed = 42 + run  # Update seed for each run\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 4.1. Simulate Treatment A\n",
    "    pA = sent_label * p_treat_given_pos + (1 - sent_label) * p_treat_given_neg\n",
    "    A = np.random.binomial(1, pA)\n",
    "    \n",
    "    # 4.2. Simulate Outcome Y\n",
    "    noise = np.random.normal(loc=0, scale=1, size=n_samples)\n",
    "    Y = beta_true * A + gamma_true * sent_label + noise\n",
    "    \n",
    "    # 4.3. Package into DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Y': Y,\n",
    "        'A': A,\n",
    "        'sentiment': sent_label\n",
    "    })\n",
    "    \n",
    "\n",
    "    # 4.4. Naive OLS (Unadjusted) using statsmodels\n",
    "    X_naive = sm.add_constant(df['A']) \n",
    "    model_naive = sm.OLS(df['Y'], X_naive).fit()\n",
    "    beta_naive = model_naive.params['A']\n",
    "    se_naive = model_naive.bse['A']\n",
    "    ci_lower_naive = beta_naive - z_score * se_naive\n",
    "    ci_upper_naive = beta_naive + z_score * se_naive\n",
    "    estimates_dict['Naive'].append(beta_naive)\n",
    "    cis_dict['Naive']['lower'].append(ci_lower_naive)\n",
    "    cis_dict['Naive']['upper'].append(ci_upper_naive)\n",
    "    print(f\"Naive OLS: β = {beta_naive:.3f}, SE = {se_naive:.3f}\")\n",
    "    \n",
    "    # 4.5. Oracle OLS (Adjusting for sentiment) using statsmodels\n",
    "    X_oracle = sm.add_constant(df[['A', 'sentiment']])\n",
    "    model_oracle = sm.OLS(df['Y'], X_oracle).fit()\n",
    "    beta_oracle = model_oracle.params['A']\n",
    "    se_oracle = model_oracle.bse['A']\n",
    "    ci_lower_oracle = beta_oracle - z_score * se_oracle\n",
    "    ci_upper_oracle = beta_oracle + z_score * se_oracle\n",
    "    estimates_dict['Oracle'].append(beta_oracle)\n",
    "    cis_dict['Oracle']['lower'].append(ci_lower_oracle)\n",
    "    cis_dict['Oracle']['upper'].append(ci_upper_oracle)\n",
    "    print(f\"Oracle OLS: β = {beta_oracle:.3f}, SE = {se_oracle:.3f}\")\n",
    "    \n",
    "    # 4.6.1. S-Learner (Linear)\n",
    "    outcome_model_linear = LinearRegression()\n",
    "    try:\n",
    "        outcome_model_linear = BaseSRegressor(outcome_model_linear) \n",
    "        s_ate_linear, s_ci_lower_linear , s_ci_upper_linear  = outcome_model_linear.estimate_ate(imdb_latent_rep, A, Y, return_ci=True)\n",
    "        estimates_dict['S-Learner (Linear)'].append(s_ate_linear[0])\n",
    "        cis_dict['S-Learner (Linear)']['lower'].append(s_ci_lower_linear[0])\n",
    "        cis_dict['S-Learner (Linear)']['upper'].append(s_ci_upper_linear[0])\n",
    "        print(f\"S-Learner (Linear): β = {s_ate_linear[0]:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: S-Learner (Linear) failed with error: {e}\")\n",
    "        estimates_dict['S-Learner (Linear)'].append(np.nan)\n",
    "        cis_dict['S-Learner (Linear)']['lower'].append(np.nan)\n",
    "        cis_dict['S-Learner (Linear)']['upper'].append(np.nan)\n",
    "    \n",
    "    # 4.6.2. S-Learner (RF) \n",
    "    outcome_model_rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "    try:\n",
    "        s_learner_rf = BaseSRegressor(outcome_model_rf) \n",
    "        s_ate_rf, s_ci_lower_rf, s_ci_upper_rf = s_learner_rf.estimate_ate(imdb_latent_rep, A, Y, return_ci=True)\n",
    "        estimates_dict['S-Learner (RF)'].append(s_ate_rf[0])\n",
    "        cis_dict['S-Learner (RF)']['lower'].append(s_ci_lower_rf[0])\n",
    "        cis_dict['S-Learner (RF)']['upper'].append(s_ci_upper_rf[0])\n",
    "        print(f\"S-Learner (RF): β = {s_ate_rf[0]:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: S-Learner (RF) failed with error: {e}\")\n",
    "        estimates_dict['S-Learner (RF)'].append(np.nan)\n",
    "        cis_dict['S-Learner (RF)']['lower'].append(np.nan)\n",
    "        cis_dict['S-Learner (RF)']['upper'].append(np.nan)\n",
    "\n",
    "    # 4.6.3. S-Learner (Lasso)\n",
    "    outcome_model_lasso = LassoCV(cv=5, n_jobs=-1, random_state=42, max_iter=5000)\n",
    "    try:\n",
    "        s_learner_lasso = BaseSRegressor(outcome_model_lasso) \n",
    "        s_ate_lasso, s_ci_lower_lasso, s_ci_upper_lasso = s_learner_lasso.estimate_ate(imdb_latent_rep, A, Y, return_ci=True)\n",
    "        estimates_dict['S-Learner (Lasso)'].append(s_ate_lasso[0])\n",
    "        cis_dict['S-Learner (Lasso)']['lower'].append(s_ci_lower_lasso[0])\n",
    "        cis_dict['S-Learner (Lasso)']['upper'].append(s_ci_upper_lasso[0])\n",
    "        print(f\"S-Learner (Lasso): β = {s_ate_lasso[0]:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: S-Learner (Lasso) failed with error: {e}\")\n",
    "        estimates_dict['S-Learner (Lasso)'].append(np.nan)\n",
    "        cis_dict['S-Learner (Lasso)']['lower'].append(np.nan)\n",
    "        cis_dict['S-Learner (Lasso)']['upper'].append(np.nan)\n",
    "\n",
    "    # 4.7. DoubleML with Linar and Random Forest Nuisance Estimators\n",
    "    # Convert imdb_latent_rep to DataFrame\n",
    "    X_dml_df = imdb_latent_rep.copy()\n",
    "\n",
    "    # Add outcome and treatment to DoubleMLData via column names\n",
    "    X_dml_df['Y'] = df['Y'].copy()\n",
    "    X_dml_df['A'] = df['A'].copy()\n",
    "\n",
    "    # Create DoubleMLData\n",
    "    data_dml = DoubleMLData(X_dml_df, \"Y\", \"A\")\n",
    "\n",
    "    # 4.7.1. DoubleML with Linear Models Estimators\n",
    "    try:\n",
    "        # Define nuisance models with linear models\n",
    "        ml_g_linear = LinearRegression()\n",
    "        ml_m_linear = LogisticRegression(penalty='l2', max_iter=1000)  # Treatment model\n",
    "    \n",
    "        # Instantiate and fit DoubleMLPLR\n",
    "        dml_plr_linear = DoubleMLPLR(data_dml, ml_g_linear, ml_m_linear, n_folds=2)\n",
    "        dml_plr_linear.fit()\n",
    "        beta_dml_linear = dml_plr_linear.coef[0]\n",
    "        se_dml_linear = dml_plr_linear.se[0]\n",
    "        estimates_dict['DML (Linear)'].append(beta_dml_linear)\n",
    "        # 95% Confidence Interval\n",
    "        ci_lower_dml_linear = beta_dml_linear - z_score * se_dml_linear\n",
    "        ci_upper_dml_linear = beta_dml_linear + z_score * se_dml_linear\n",
    "        cis_dict['DML (Linear)']['lower'].append(ci_lower_dml_linear)\n",
    "        cis_dict['DML (Linear)']['upper'].append(ci_upper_dml_linear)\n",
    "        print(f\"DML (Linear): β = {beta_dml_linear:.3f}, SE = {se_dml_linear:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML (NN) failed with error: {e}\")\n",
    "        estimates_dict['DML'].append(np.nan)\n",
    "        cis_dict['DML (Linear)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (Linear)']['upper'].append(np.nan)\n",
    "    \n",
    "    # 4.7.2. DoubleML with Random Forest Nuisance Estimators\n",
    "    try:\n",
    "        # Define nuisance models with neural networks\n",
    "        ml_g_rf = RandomForestRegressor(n_estimators=10, random_state=42)\n",
    "        ml_m_rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "    \n",
    "        # Instantiate and fit DoubleMLPLR\n",
    "        dml_plr_rf = DoubleMLPLR(data_dml, ml_g_rf, ml_m_rf, n_folds=2) \n",
    "        dml_plr_rf.fit()\n",
    "        beta_dml_rf = dml_plr_rf.coef[0]\n",
    "        se_dml_rf = dml_plr_rf.se[0]\n",
    "        estimates_dict['DML (RF)'].append(beta_dml_rf)\n",
    "        # 95% Confidence Interval\n",
    "        ci_lower_dml_rf = beta_dml_rf - z_score * se_dml_rf\n",
    "        ci_upper_dml_rf = beta_dml_rf + z_score * se_dml_rf\n",
    "        cis_dict['DML (RF)']['lower'].append(ci_lower_dml_rf)\n",
    "        cis_dict['DML (RF)']['upper'].append(ci_upper_dml_rf)\n",
    "        print(f\"DML (RF): β = {beta_dml_rf:.3f}, SE = {se_dml_rf:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML failed with error: {e}\")\n",
    "        estimates_dict['DML (RF)'].append(np.nan)\n",
    "        cis_dict['DML (RF)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (RF)']['upper'].append(np.nan)\n",
    "\n",
    "    # 4.7.3. DoubleML with Lasso Nuisance Estimators\n",
    "    try:\n",
    "        # Define nuisance models with neural networks\n",
    "        ml_g_lasso = LassoCV(cv=5, n_jobs=-1, random_state=42, max_iter=5000)\n",
    "        ml_m_lasso = LogisticRegressionCV(penalty='l1', cv=5, n_jobs=-1, \n",
    "                                          random_state=42, solver='saga', max_iter=10000)\n",
    "    \n",
    "        # Instantiate and fit DoubleMLPLR\n",
    "        dml_plr_lasso = DoubleMLPLR(data_dml, ml_g_lasso, ml_m_lasso, n_folds=2)  \n",
    "        dml_plr_lasso.fit()\n",
    "        beta_dml_lasso = dml_plr_lasso.coef[0]\n",
    "        se_dml_lasso = dml_plr_lasso.se[0]\n",
    "        estimates_dict['DML (Lasso)'].append(beta_dml_lasso)\n",
    "        # 95% Confidence Interval\n",
    "        ci_lower_dml_lasso = beta_dml_lasso - z_score * se_dml_lasso \n",
    "        ci_upper_dml_lasso = beta_dml_lasso + z_score * se_dml_lasso\n",
    "        cis_dict['DML (Lasso)']['lower'].append(ci_lower_dml_lasso)\n",
    "        cis_dict['DML (Lasso)']['upper'].append(ci_upper_dml_lasso)\n",
    "        print(f\"DML (Lasso): β = {beta_dml_lasso:.3f}, SE = {se_dml_lasso:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML (Lasso) failed with error: {e}\")\n",
    "        estimates_dict['DML (Lasso)'].append(np.nan)\n",
    "        cis_dict['DML (Lasso)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (Lasso)']['upper'].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a directory for the experiment and save the results\n",
    "experiment_name = \"exp_results\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_dir = os.path.join(results_dir, model_name, experiment_name, timestamp)\n",
    "save_results(experiment_dir, estimates_dict, cis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the previous experiment\n",
    "estimates_dict, cis_dict = load_results(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ATE estimates with confidence intervals\n",
    "plot_ate_estimates(\n",
    "    estimates_dict=estimates_dict,\n",
    "    cis_dict=cis_dict,\n",
    "    plot_name=\"ate_estimates_label_conf_imdb\",\n",
    "    save_dir=experiment_dir,\n",
    "    ate_true=2.0,\n",
    "    n_runs=5,\n",
    "    figsize=(16, 8),\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretrained-causal-adj)",
   "language": "python",
   "name": "pretrained-causal-adj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
