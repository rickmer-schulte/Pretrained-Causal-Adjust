{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ATE estimation\n",
    "import statsmodels.api as sm\n",
    "from doubleml import DoubleMLData, DoubleMLPLR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# DML CNN utils\n",
    "from dml_utils.doubleml_image import DoubleMLPLRImage\n",
    "from dml_utils.xray_dataset import XRayDataset\n",
    "from dml_utils.cnn_regressor import CNNRegressor\n",
    "from dml_utils.preprocess import dml_preprocess_pipeline\n",
    "from dml_utils.models import CNN_2, CNN_5\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Custom modules\n",
    "from feature_extraction.pretrained_models_xrv import load_torchxrayvision_model, extract_features_from_folder\n",
    "from utils.project import set_root\n",
    "from utils.io import save_results, load_results\n",
    "from visualization.plotting import plot_ate_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory, dataset directory and directory for saving results\n",
    "set_root()\n",
    "dataset_dir = \"data/xray/raw/all_unique\"\n",
    "results_dir = \"results/dml_cnn/xray\"\n",
    "\n",
    "# Define the model name and path for saving results\n",
    "model_name = \"densenet121-res224-all\"  # Pretrained model name\n",
    "save_dir = f\"data/xray/representations/{model_name}\"\n",
    "\n",
    "# Define file paths\n",
    "features_path = os.path.join(save_dir, \"latent_features.npy\")\n",
    "labels_path = os.path.join(save_dir, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction and saving (Only if the features and labels do not already exist)\n",
    "if not os.path.exists(features_path) or not os.path.exists(labels_path):\n",
    "    print(f\"Extracting features using model '{model_name}'...\")\n",
    "    \n",
    "    # Extract features and save them\n",
    "    model = load_torchxrayvision_model(model_name)\n",
    "    all_features, labels = extract_features_from_folder(\n",
    "        dataset_dir,\n",
    "        model,\n",
    "        device='cpu',\n",
    "        batch_size=32,\n",
    "        save_path=save_dir\n",
    "    )\n",
    "    \n",
    "    print(f\"Features extracted and saved to: {save_dir}\")\n",
    "else:\n",
    "    print(f\"Features already exist in {save_dir}. Skipping extraction.\")\n",
    "\n",
    "# Load extracted features\n",
    "all_features_pretrained = np.load(features_path)\n",
    "all_labels_pretrained = np.load(labels_path)\n",
    "n_samples_total = len(all_labels_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATE Estimation using Double Machine Learning with/without pre-trained representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Dataset and DataLoader for DML with CNN regressors\n",
    "dataset = XRayDataset(dataset_dir, transform=dml_preprocess_pipeline())\n",
    "\n",
    "batch_size = n_samples_total # Use all samples avialbale and subsample later\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture used for the outcome and propensity score models \n",
    "cnn_type = \"cnn2\"  # Choose between \"cnn2\" and \"cnn5\"\n",
    "if cnn_type == \"cnn2\":\n",
    "    # Initialize raw PyTorch CNN models\n",
    "    cnn_for_outcome = CNN_2(output_dim=1, is_classifier=False)  # For continuous outcome\n",
    "    cnn_for_treatment = CNN_2(output_dim=1, is_classifier=True)  # For binary treatment\n",
    "elif cnn_type == \"cnn5\":\n",
    "    # Initialize raw PyTorch CNN models\n",
    "    cnn_for_outcome = CNN_5(output_dim=1, is_classifier=False)  # For continuous outcome\n",
    "    cnn_for_treatment = CNN_5(output_dim=1, is_classifier=True)  # For binary treatment\n",
    "else:\n",
    "    raise ValueError(\"Invalid CNN type specified.\")\n",
    "\n",
    "# Wrap models using the CNNRegressor class\n",
    "cnn_for_outcome = CNNRegressor(cnn_for_outcome, epochs=30, is_classifier=False)\n",
    "cnn_for_treatment = CNNRegressor(cnn_for_treatment, epochs=30, is_classifier=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Confounding Simualtion and ATE Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Define simulation parameters\n",
    "beta_true = 2.0     # True effect of A on Y\n",
    "gamma_true = -2   # Effect of pneumonia on Y\n",
    "p_treat_given_pneu = 0.7    # Probability of treatment if pneumonia\n",
    "p_treat_given_normal = 0.3  # Probability of treatment if normal\n",
    "\n",
    "# 1.2 Set up training loop parameters\n",
    "n_runs = 5  \n",
    "n_samples_run = 500  # Number of samples to use in each run\n",
    "ci_alpha_level = 0.05  # Confidence interval alpha level\n",
    "z_score = norm.ppf(1 - ci_alpha_level / 2)  # Z-score for 1-alpha confidence intervals\n",
    "\n",
    "# 1.3 Initialize storage for estimates and confidence intervals\n",
    "methods = ['Naive', 'Oracle', 'DML (Pre-trained)', 'DML (CNN)']\n",
    "estimates_dict = {method: [] for method in methods}\n",
    "cis_dict = {method: {'se': [], 'lower': [], 'upper': []} for method in methods}\n",
    "\n",
    "# 1.4. Load image data (unshuffled)\n",
    "all_images, all_labels, filenames = next(iter(dataloader))\n",
    "label_mapping = {\"NORMAL\": 0, \"PNEUMONIA\": 1}\n",
    "all_labels = np.array([label_mapping[label] for label in all_labels])\n",
    "all_labels = all_labels.astype(int)  # Ensure binary (0/1) labels for pneumonia\n",
    "\n",
    "# Ensure the labels match between the images and the representations\n",
    "assert np.array_equal(all_labels, all_labels_pretrained), \"Labels do not match between dataset and representations.\"\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42\n",
    "\n",
    "for run in range(n_runs):\n",
    "    print(f\"\\n--- Simulation Run {run + 1} ---\")\n",
    "    # Set a unique seed for each run for variability\n",
    "    seed = seed + 2  # Update seed for each run\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 2.1. Generate random indices for shuffling\n",
    "    random_indices = np.random.permutation(n_samples_total)\n",
    "    \n",
    "    # 2.2. Shuffle both images and representations using the same indices\n",
    "    images = all_images[random_indices][:n_samples_run]\n",
    "    labels = all_labels[random_indices][:n_samples_run]\n",
    "    features_pretrained = all_features_pretrained[random_indices][:n_samples_run]\n",
    "    labels_pretrained = all_labels_pretrained[random_indices][:n_samples_run]\n",
    "    \n",
    "    # Sanity check to ensure labels are still matching\n",
    "    assert np.array_equal(labels, labels_pretrained), \"Labels do not match after shuffling.\"\n",
    "    print(f\"Sampled {n_samples_run} observations of {n_samples_total} for this run.\")\n",
    "\n",
    "    # 3.1 Simulate Treatment A\n",
    "    pA = labels * p_treat_given_pneu + (1 - labels) * p_treat_given_normal\n",
    "    A = np.random.binomial(1, pA)\n",
    "\n",
    "    # 3.2. Simulate Outcome Y\n",
    "    noise = np.random.normal(loc=0, scale=1, size=n_samples_run)\n",
    "    Y = beta_true * A + gamma_true * labels + noise\n",
    "\n",
    "    # Store data in DataFrame\n",
    "    df = pd.DataFrame({'Y': Y, 'A': A, 'pneumonia': labels})\n",
    "\n",
    "    ## 4.4. Naive OLS (Unadjusted)\n",
    "    X_naive = sm.add_constant(df['A']) \n",
    "    model_naive = sm.OLS(df['Y'], X_naive).fit()\n",
    "    beta_naive = model_naive.params['A']\n",
    "    se_naive = model_naive.bse['A']\n",
    "    ci_lower_naive = beta_naive - z_score * se_naive\n",
    "    ci_upper_naive = beta_naive + z_score * se_naive\n",
    "    estimates_dict['Naive'].append(beta_naive)\n",
    "    cis_dict['Naive']['lower'].append(ci_lower_naive)\n",
    "    cis_dict['Naive']['upper'].append(ci_upper_naive)\n",
    "    print(f\"Naive OLS: β = {beta_naive:.3f}, SE = {se_naive:.3f}\")\n",
    "    \n",
    "    ## 4.5. Oracle OLS (Adjusting for pneumonia)\n",
    "    X_oracle = sm.add_constant(df[['A', 'pneumonia']])\n",
    "    model_oracle = sm.OLS(df['Y'], X_oracle).fit()\n",
    "    beta_oracle = model_oracle.params['A']\n",
    "    se_oracle = model_oracle.bse['A']\n",
    "    ci_lower_oracle = beta_oracle - z_score * se_oracle\n",
    "    ci_upper_oracle = beta_oracle + z_score * se_oracle\n",
    "    estimates_dict['Oracle'].append(beta_oracle)\n",
    "    cis_dict['Oracle']['lower'].append(ci_lower_oracle)\n",
    "    cis_dict['Oracle']['upper'].append(ci_upper_oracle)\n",
    "    print(f\"Oracle OLS: β = {beta_oracle:.3f}, SE = {se_oracle:.3f}\")\n",
    "\n",
    "    ## 4.6. DML (Pre-Trained and CNNs)\n",
    "    # Convert pre-trained features to DataFrame\n",
    "    X_dml_df = pd.DataFrame(\n",
    "        features_pretrained,\n",
    "        columns=[f\"feat_{i}\" for i in range(features_pretrained.shape[1])]\n",
    "    )\n",
    "\n",
    "    # Add outcome and treatment to DoubleMLData via column names\n",
    "    X_dml_df['Y'] = df['Y'].copy()\n",
    "    X_dml_df['A'] = df['A'].copy()\n",
    "\n",
    "    # Create DoubleMLData\n",
    "    data_dml = DoubleMLData(X_dml_df, \"Y\", \"A\")\n",
    "\n",
    "    # 4.6.1. DML (Pre-Trained): DML with linear models nuisance functions from pre-trained representations\n",
    "    try:\n",
    "        # Define nuisance models with linear models\n",
    "        ml_g_linear = LinearRegression() # Outcome model\n",
    "        ml_m_linear = LogisticRegression()  # Treatment model\n",
    "\n",
    "    \n",
    "        # Instantiate and fit DoubleMLPLR\n",
    "        dml_plr_linear = DoubleMLPLR(data_dml, ml_g_linear, ml_m_linear, n_folds=2) \n",
    "        dml_plr_linear.fit()\n",
    "        beta_dml_linear = dml_plr_linear.coef[0]\n",
    "        se_dml_linear = dml_plr_linear.se[0]\n",
    "        estimates_dict['DML (Pre-trained)'].append(beta_dml_linear)\n",
    "        # 95% Confidence Interval\n",
    "        ci_lower_dml_linear = beta_dml_linear - z_score * se_dml_linear\n",
    "        ci_upper_dml_linear = beta_dml_linear + z_score * se_dml_linear\n",
    "        cis_dict['DML (Pre-trained)']['lower'].append(ci_lower_dml_linear)\n",
    "        cis_dict['DML (Pre-trained)']['upper'].append(ci_upper_dml_linear)\n",
    "        print(f\"DML (Pre-trained): β = {beta_dml_linear:.3f}, SE = {se_dml_linear:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML (Pre-trained) failed with error: {e}\")\n",
    "        estimates_dict['DML (Pre-trained)'].append(np.nan)\n",
    "        cis_dict['DML (Pre-trained)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (Pre-trained)']['upper'].append(np.nan)\n",
    "\n",
    "    ## 4.6.2. DML (CNN): DML with CNNs as nuisance functions\n",
    "    # Initialize DoubleMLPLRImage with CNNs\n",
    "    try:\n",
    "        # Initialize DoubleMLPLRImage with CNNs\n",
    "        dml_plr_image = DoubleMLPLRImage(\n",
    "            X=images.numpy(),\n",
    "            y=Y,\n",
    "            d=A,\n",
    "            ml_l=cnn_for_outcome,\n",
    "            ml_m=cnn_for_treatment,\n",
    "            n_folds=2,\n",
    "            n_rep=1\n",
    "        )\n",
    "    \n",
    "        # Fit the model\n",
    "        dml_plr_image.fit()\n",
    "    \n",
    "        # Collect results\n",
    "        beta_dml = dml_plr_image.coef\n",
    "        se_dml = dml_plr_image.se\n",
    "        estimates_dict['DML (CNN)'].append(beta_dml)\n",
    "        ci_lower_dml = beta_dml - z_score * se_dml\n",
    "        ci_upper_dml = beta_dml + z_score * se_dml\n",
    "        cis_dict['DML (CNN)']['se'].append(se_dml)\n",
    "        cis_dict['DML (CNN)']['lower'].append(ci_lower_dml)\n",
    "        cis_dict['DML (CNN)']['upper'].append(ci_upper_dml)\n",
    "        print(f\"DML (CNN): β = {beta_dml:.3f}, SE = {se_dml:.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Run {run+1}: DML (CNN) failed with error: {e}\")\n",
    "        estimates_dict['DML (CNN)'].append(np.nan)\n",
    "        cis_dict['DML (CNN)']['se'].append(np.nan)\n",
    "        cis_dict['DML (CNN)']['lower'].append(np.nan)\n",
    "        cis_dict['DML (CNN)']['upper'].append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a directory for the experiment and save the results\n",
    "experiment_name = f\"{cnn_type}_{n_samples_run}\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_dir = os.path.join(results_dir, model_name, experiment_name, timestamp)\n",
    "save_results(experiment_dir, estimates_dict, cis_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results from the previous experiment\n",
    "estimates_dict, cis_dict = load_results(experiment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ATE estimates with confidence intervals\n",
    "plot_ate_estimates(\n",
    "    estimates_dict=estimates_dict,\n",
    "    cis_dict=cis_dict,\n",
    "    plot_name=f'ate_label_conf_xray_{experiment_name}',\n",
    "    save_dir=experiment_dir,\n",
    "    ate_true=beta_true,\n",
    "    n_runs=n_runs,\n",
    "    vert_diff=0.03,\n",
    "    label_break=False,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pretrained-causal-adj)",
   "language": "python",
   "name": "pretrained-causal-adj"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
